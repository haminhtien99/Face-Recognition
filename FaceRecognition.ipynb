{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf5fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d685c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4bdc2",
   "metadata": {},
   "source": [
    "# Face Capturing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5fe4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = './data/test_images/'\n",
    "count = 50 #Количество изображений каждого пользователя\n",
    "# Ввести имя пользователя\n",
    "usr_name = input(\"Input user name: \")\n",
    "USR_PATH = os.path.join(IMG_PATH, usr_name)\n",
    "leap = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7819818",
   "metadata": {},
   "source": [
    "MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3a11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_process=False так как нам не нужна нормализация при сохранении изображений\n",
    "mtcnn = MTCNN(margin = 20, keep_all=False, select_largest = True, post_process=False, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137a51f",
   "metadata": {},
   "source": [
    "Снимать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c43198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/ha/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)\n",
    "\n",
    "while cap.isOpened() and count:\n",
    "    isSuccess, frame = cap.read()\n",
    "    if mtcnn(frame) is not None and leap%2:\n",
    "        # Использовать datetime для сохранения информации изображений пользователя\n",
    "        path = str(USR_PATH+'/{}.jpg'.format(str(datetime.now())[:-7].replace(\":\",\"-\").replace(\" \",\"-\")+str(count)))\n",
    "        face_img = mtcnn(frame, save_path = path)\n",
    "        count-=1\n",
    "    leap+=1\n",
    "    cv2.imshow('Face Capturing', frame)\n",
    "    if cv2.waitKey(1)&0xFF == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e295f",
   "metadata": {},
   "source": [
    "# Создать список изображений каждого пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205c41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = './data/test_images'\n",
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed4c0e",
   "metadata": {},
   "source": [
    "Нормализация в [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad86d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(img):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            fixed_image_standardization\n",
    "        ])\n",
    "    return transform(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d08494",
   "metadata": {},
   "source": [
    "Обучение с использованием Pretrained models CASIA-Webface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify = False чтобы получить Feature Vector в 512-мерном\n",
    "model = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained=\"casia-webface\"\n",
    ").to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87a0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "names = []\n",
    "\n",
    "for usr in os.listdir(IMG_PATH):\n",
    "    embeds = []\n",
    "    # Получить 50 Feature Vector из 50 изображений\n",
    "    for file in glob.glob(os.path.join(IMG_PATH, usr)+'/*.jpg'):\n",
    "        # print(usr)\n",
    "        try:\n",
    "            img = Image.open(file)\n",
    "        except:\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            embeds.append(model(trans(img).to(device).unsqueeze(0))) \n",
    "    \n",
    "    if len(embeds) == 0:\n",
    "        continue\n",
    "\n",
    "    # Нужен только один вектор из 50 векторов\n",
    "    # Найти среднее значение каждой компонеты всех 50 векторов\n",
    "    embedding = torch.cat(embeds).mean(0, keepdim=True) \n",
    "    \n",
    "    # Добавить в список пользователей\n",
    "    embeddings.append(embedding) \n",
    "    names.append(usr)\n",
    "embeddings = torch.cat(embeddings) #[n,512]\n",
    "names = np.array(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d706aa6",
   "metadata": {},
   "source": [
    "Сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8b892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update Completed! There are 1 people in FaceLists\n"
     ]
    }
   ],
   "source": [
    "if device == 'cpu':\n",
    "    torch.save(embeddings, DATA_PATH+\"/faceslistCPU.pth\")\n",
    "else:\n",
    "    torch.save(embeddings, DATA_PATH+\"/faceslist.pth\")\n",
    "np.save(DATA_PATH+\"/usernames\", names)\n",
    "print('Update Completed! There are {0} people in FaceLists'.format(names.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a295dd",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8851e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = (640,480)\n",
    "IMG_PATH = './data/test_images'\n",
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c3839",
   "metadata": {},
   "source": [
    "Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43caed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нормализация в [-1, 1]\n",
    "def trans(img):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            fixed_image_standardization\n",
    "        ])\n",
    "    return transform(img)\n",
    "\n",
    "#Получить список пользователей и Feature Vector\n",
    "def load_faceslist():\n",
    "    if device == 'cpu':\n",
    "        embeds = torch.load(DATA_PATH+'/faceslistCPU.pth')\n",
    "    else:\n",
    "        embeds = torch.load(DATA_PATH+'/faceslist.pth')\n",
    "    names = np.load(DATA_PATH+'/usernames.npy')\n",
    "    return embeds, names\n",
    "\n",
    "#Детектировать лицо и получить координаты ограничительной рамки\n",
    "power = pow(10, 6)\n",
    "def extract_face(box, img, margin=20):\n",
    "    face_size = 160\n",
    "    img_size = frame_size\n",
    "    margin = [\n",
    "        margin * (box[2] - box[0]) / (face_size - margin),\n",
    "        margin * (box[3] - box[1]) / (face_size - margin),\n",
    "    ]\n",
    "    box = [\n",
    "        int(max(box[0] - margin[0] / 2, 0)),\n",
    "        int(max(box[1] - margin[1] / 2, 0)),\n",
    "        int(min(box[2] + margin[0] / 2, img_size[0])),\n",
    "        int(min(box[3] + margin[1] / 2, img_size[1])),\n",
    "    ]\n",
    "    img = img[box[1]:box[3], box[0]:box[2]]\n",
    "    face = cv2.resize(img,(face_size, face_size), interpolation=cv2.INTER_AREA)\n",
    "    face = Image.fromarray(face)\n",
    "    return face\n",
    "\n",
    "# Оценка классификации детектированного лица face - похожа на kNN (k =1)\n",
    "def inference(model, face, local_embeds, threshold = 3):\n",
    "    embeds = []\n",
    "    embeds.append(model(trans(face).to(device).unsqueeze(0)))\n",
    "    detect_embeds = torch.cat(embeds) \n",
    "\n",
    "    #Считать расстояния между вектором detect_embeds и каждым вектором из local_embeds\n",
    "    #Получить матрицу расстояния [n,512]\n",
    "    norm_diff = detect_embeds.unsqueeze(-1) - torch.transpose(local_embeds, 0, 1).unsqueeze(0)\n",
    "    #Расстояние есть сумма квадратов каждой компоненты векторов\n",
    "    norm_score = torch.sum(torch.pow(norm_diff, 2), dim=1) \n",
    "    \n",
    "    min_dist, embed_idx = torch.min(norm_score, dim = 1)\n",
    "    print(min_dist*power, names[embed_idx])\n",
    "    \n",
    "    if min_dist*power > threshold:\n",
    "        return -1, -1\n",
    "    else:\n",
    "        return embed_idx, min_dist.double()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519531e",
   "metadata": {},
   "source": [
    "Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f13a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify = False чтобы получить Feature Vector в 512-мерном\n",
    "model = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained=\"casia-webface\"\n",
    ").to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c36fe",
   "metadata": {},
   "source": [
    "MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7bd1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(thresholds= [0.7, 0.7, 0.8] ,keep_all=True, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206676bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "\n",
    "embeddings, names = load_faceslist()\n",
    "while cap.isOpened():\n",
    "    isSuccess, frame = cap.read()\n",
    "    if isSuccess:\n",
    "        boxes, _ = mtcnn.detect(frame)\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                bbox = list(map(int,box.tolist()))\n",
    "                face = extract_face(bbox, frame)\n",
    "                idx, score = inference(model, face, embeddings)\n",
    "                \n",
    "                # Показать bounding box\n",
    "                if idx != -1:\n",
    "                    frame = cv2.rectangle(frame, (bbox[0],bbox[1]), (bbox[2],bbox[3]), (0,0,255), 6)\n",
    "                    score = torch.Tensor.cpu(score[0]).detach().numpy()*power\n",
    "                    frame = cv2.putText(frame, names[idx] + '_{:.2f}'.format(score), (bbox[0],bbox[1]), cv2.FONT_HERSHEY_DUPLEX, 2, (0,255,0), 2, cv2.LINE_8)\n",
    "                else:\n",
    "                    frame = cv2.rectangle(frame, (bbox[0],bbox[1]), (bbox[2],bbox[3]), (0,0,255), 6)\n",
    "                    frame = cv2.putText(frame,'Unknown', (bbox[0],bbox[1]), cv2.FONT_HERSHEY_DUPLEX, 2, (0,255,0), 2, cv2.LINE_8)\n",
    "                \n",
    "                # Показать 5 Точек в лице\n",
    "                # if(not isinstance(points_list, list)):\n",
    "                    # points_list= points_list.tolist()\n",
    "                # for usr in points_list:\n",
    "                    # for points in usr:\n",
    "                        # frame = cv2.circle(frame, (int(points[0]), int(points[1])), radius=0, color=(0,0,255), thickness=10)\n",
    "        \n",
    "        \n",
    "        new_frame_time = time.time()\n",
    "        fps = 1/(new_frame_time-prev_frame_time)\n",
    "        prev_frame_time = new_frame_time\n",
    "        fps = str(int(fps))\n",
    "        cv2.putText(frame, fps, (7, 70), cv2.FONT_HERSHEY_DUPLEX, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1)&0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#Нажать ESC чтобы выключить\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
